# HealthInsuranceModel ğŸš€ â€“ Intelligent Document Q&A

**A HackRx Submission**  
LLM-Powered Intelligent Queryâ€“Retrieval System

---

## ğŸ“Œ Problem Statement

Enterprises in **insurance**, **legal**, and **HR** are drowning in massive, complex documents.  
Manually finding specific clauses or answers is:

- **Slow & Inefficient** â€“ Experts spend hours searching for information.
- **Costly** â€“ Wasted manpower and reliance on specialists.
- **Risky** â€“ Misinterpretations lead to compliance failures, legal liabilities, and poor decisions.

The core challenge: **Unlock valuable structured knowledge trapped inside unstructured text**.

---

## ğŸ’¡ Solution â€“ ClausePilot

ClausePilot is an **Intelligent Retrieval-Augmented Generation (RAG) system** that transforms dense documents into interactive knowledge bases.

- Upload or provide a document URL.
- Ask **natural language questions**.
- Get **instant, accurate, explainable answers** with structured justifications.

---

## ğŸ› ï¸ Tech Stack

| Component       | Technology Used             |
| --------------- | --------------------------- |
| Backend API     | FastAPI                     |
| LLM             | Google Gemini 1.5 Flash     |
| Embeddings      | Google embedding-001        |
| Vector Database | FAISS (in-memory, cached)   |
| Parsing         | PyMuPDF, python-docx        |
| Concurrency     | Python `concurrent.futures` |

---

## âš™ï¸ How It Works

1. **ğŸ“¥ Ingestion & Parsing** â€“ Downloads document (.pdf, .docx, .eml) & extracts text.
2. **âœ‚ï¸ Chunking & Embedding** â€“ Splits text into chunks & generates embeddings.
3. **ğŸ§  Indexing** â€“ Stores embeddings in FAISS index for fast semantic search.
4. **ğŸ” Retrieval** â€“ Converts query into an embedding & retrieves relevant chunks.
5. **ğŸ’¬ Generation & Justification** â€“ Sends retrieved chunks + question to Gemini LLM for a precise answer & explanation in JSON format.

---

## âœ¨ Key Advantages

- **High Accuracy & Explainability** â€“ JSON answers with clause references.
- **Token Efficiency** â€“ Only relevant chunks sent to the LLM.
- **Speed** â€“ Cached FAISS index & concurrent processing.
- **Modularity** â€“ Swap in other LLMs or vector DBs.

---

## ğŸ”® Future Enhancements

- Managed vector DB (Pinecone) for scalability.
- Interactive web UI for real-time Q&A.
- Comparative queries across multiple documents.
- Hybrid semantic + keyword search.

---

## ğŸ“‚ Project Structure

```
ClausePilot/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/ramgopal-reddy/HealthInsuranceModel.git
cd HealthInsuranceModel
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set environment variables

Create a `.env` file with your API keys:

```bash
GEMINI_API_KEY=your_gemini_api_key_here
```

### 4ï¸âƒ£ Run the API

```bash
uvicorn app.main:app --reload
```

API will be live at: `http://127.0.0.1:8000` (similar)

---

## ğŸ“¬ API Usage

**POST** `/hackrx/run`  
Send:

```json
{
  "document_url": "https://example.com/sample.pdf",
  "questions": [
    "What is the coverage period?",
    "What is the cancellation policy?"
  ]
}
```

Returns:

```json
[
  {
    "question": "...",
    "answer": "...",
    "justification": "..."
  }
]
```

---

## ğŸ§‘â€ğŸ’» Team â€“

- **Lead AI/ML Engineer** â€“ Architected RAG pipeline & optimized embeddings.
- **Backend & API Developer** â€“ Built scalable, low-latency FastAPI service.

---

## ğŸ“œ License

MIT License â€“ see [LICENSE](LICENSE) for details.
